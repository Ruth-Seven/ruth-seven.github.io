---
title: CSAPP笔记5-程序优化
thumbnail: 'http://static.come2rss.xyz/尼尔机械.jpg'
toc: true
top: 10
categories:
date: 2020-08-13 15:46:49
tags:
---

GCC为我们C++语言提供了优秀的自动优化方法，`-O1,-O2,-Og`可以配置不同优化程度。但是GCC的优化也有局限性，它小心翼翼地保护不能确定结果的代码，比如：下述代码中，如果p2指向了v的最后一个元素，其计算结果和p2指向一个`int data = (*v)[(int)v.size() - 1]`的结果完全不同。

<!-- more -->

```c
int f(vector<int> *v, int *p2){
	for(int i = 0; i < v->size(); i++)
		*p2 = *p2 * (*v + i);
}
```

## 程序级优化方法

上述代码可以有三种可以讨论的方向。

> 程序优化指标CPE：每个元素（泛指，比如一组指令，一段语句，一句汇编都可以是一个元素）所花费的平均CPU周期。

### 减少不必要的函数调用

如果计算过程不存在改变vector的长度，`v->size()`应该避免多次调用，因为计算结果都是相同的。但是编译器不会把函数移动出去，因为它不知道`for`循环体的副作用。程序员应该主动移动该类函数。

### 减少不必要的内存引用

上述例子中`p2`被不断的读，写，同时体现在编译语言上就不断的从内存中读，到内存中写。然而更好的方法就是定义一个暂时变量，从而在寄存器中保存结果，大幅减少读写指令。同样的因为指针未知指向，编译器也不会主动增加变量来暂存结果，只能由程序员手动更改代码。



### 循环展开

可以在一次循环中计算原本循环中多次计算的结果。



## 从现代处理器理解程序优化

处理器的不同单元有分支、算数运算、加载和存储多个功能，每个单元负责执行不同指令的不同操作。加载单元的数量限制了数据量的上限，称之为**吞吐量界限**。延迟也就是完成运算的需要的总时间。**延迟界限**是顺序指令执行的上限。

另外，**发射时间**指两个同类型的运算之间需要的最小周期数，**容量**指能够执行单元指令的功能单元数量。

从数据流图的角度分析代码瓶颈：

```c++
double mult(int a[], int len){
    int i = 1;
    long res = 1;
    for(; i < len; i++){
        res = rse * a[i];
    }
    return res;
}
```

仅仅关注循环翻译的代码可以得到：

![image-20200822134523286](http://static.come2rss.xyz/image-20200822134523286.png)

> 明显的有，存储器含义如下
>
> %rax: a[0] + len * 8
>
> %rdx:a[0] + i * 8
>
> %xmm0: res

把寄存器和指令关系联系起来，可以得出：

![image-20200822134541847](http://static.come2rss.xyz/image-20200822134541847.png)

把图形变形一下，然后留下迭代中变化的寄存器和使其变化的指令，可得(b)。

![image-20200822135156013](http://static.come2rss.xyz/image-20200822135156013.png)

讲多个迭代的数据流图拼接起来可得：

![image-20200822135407665](http://static.come2rss.xyz/image-20200822135407665.png)

其中明显的有关键路径，也是整个迭代执行的瓶颈，就是说迭代的CPE等于关键路径的CPE。

> 容易混淆的是，关键路径查找失败，注意寄存器要相同。



### 循环展开

也就是一次循环中计算多次迭代的值，已达到减少迭代的次数的目的。可以提高效率，但是CPE不会超过延迟界限，这是因为本质上将经过循环展开的代码所有执行过程展示，执行op数量和原有迭代相同。

> 编译器在优化等级3以上就自动循环展开。

### 提高并行性

令人兴奋的是，提高并行性的方法可以打破延迟界限，但是无法突破吞吐界限。

#### 多个累计变量

将多个迭代拆分成每次迭代中计算多个不相互影响的计算式，从而降低迭代次数。

比如以下代码可以称为2*2循环展开：

> 前一个2指循环展开的计算式，
>
> 后一个2指一个迭代计算的变量。

```c
long res1 = 1, res2 = 1;
for(int i = 1; i < len; i += 2){
    res1 *= a[i];
    res2 *= a[i + 1];
}
res = res1 * res2;
```

可以猜出，这两条计算指令可以并行处理，而且在数据流图上也出现两条关键路径。假设乘法的CPE为5，那么这个迭代的CPE为$5/2= 2.5$。

![image-20200822140741065](http://static.come2rss.xyz/image-20200822140741065.png)

> 不过要小心，这种改变了计算顺序的优化方法，可能会导致计算结果的突变。比如浮点数乘法计算的溢出（上溢，下溢），浮点数的加法和乘法是不可结合的，原因如上。不过一般来说，极端数据模式的出现概率很低，而且一般来说，提高代码性能远远比防止极端数据出现更重要。
>
> 放心的是，整数加法和乘法可以结合。



#### 重新结合变化



如下图，把计算OP顺序改变，可以得到近乎一半的性能提升。

![image-20200822142413222](http://static.come2rss.xyz/image-20200822142413222.png)

原因仍然可以从数据流图中寻找：

![image-20200822142726779](http://static.come2rss.xyz/image-20200822142726779.png)

至于另一条的数据流图，也很好画，结果正是两个`mul`在一个迭代中的关键路径上。

> AVX向量指令是Intel引入的SSE指令。（SSE是Streaming SIMD Extensions的缩写，SIMP为Single-In-struction, Multiple-Data，即单指令，多数据流的缩写）当前的AVX寄存器长为32B，每一个寄存器可以存放8个32bits或者4个64bits的数字。
>
> `vmulps  (%rcx), %ymm0, %ymm1`可以读出8个数据进行相乘，$a_i=a_i*b_i, 0<= i<8$。
>
> 可以对32位运算的效率提高8倍，64位计算的效率提高4倍。
>
> 但，AVX指令无法产生64位整数的并行乘法指令。

#### 其他因素

由于循环内部暂存量过多，寄存器数量不够，反而导致需要在栈中暂时保存，这会到时效率变低。

分支语句尽可能转化条件数据传送，否则如果预测错误效率会降很多。

> 以下就是条件数据传送：
>
> v = cal_exper1；
>
> n = cal_exper2;
>
> if(t) rse = v;
>
> 一般到的if-else形式语句就是条件操作传送。



## 综合应用

Unix提供了一个GPROF可以分析函数调用情况，以便我们优化代码。

### 操作步骤

```shell
gcc -Og -pg prog.c -o prog //-pg 避免内联函数变形，使用GPROF剖析
./prog file.txt  //产生gmon.out
grpof prog //分析数据
```

### 解析

剖析第一部分容易看出：

![image-20200822145100931](http://static.come2rss.xyz/image-20200822145100931.png)

第二部分：

前两行指`find_ele_rec`被`find_ele_rec`和`insret_string`的调用情况，第三行指`find_ele_rec`总被调用情况，后两行指`find_ele_rec`调用的两个函数情况。

![image-20200822145200831](http://static.come2rss.xyz/image-20200822145200831.png)

可以看出`find_ele_rec`是一个递归函数，而且……

> GPROF计时不准。基于间段计时中断的机制，典型的中断时间是1ms，容易对执行时间不长的程序误判时长。对于计时长的GPROF的程序计时显得准确。
>
> 如果没有执行内联替换则调用信息准确。
>
> 不会显示对库函数的计时，除非用一个包装函数（wrapper function）
>
> 